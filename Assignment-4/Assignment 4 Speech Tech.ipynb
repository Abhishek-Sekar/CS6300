{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and arranging data\n",
    "# All the mfcc features for each utterance is compiled in a folder called MFCC\n",
    "train_speakers = ['ac',  'bh',  'cg',  'dg',  'eg',  'hg',  'il',  'jn',  'kh',  'la',\n",
    "'ag',  'bi',  'cl',  'ea',  'ei',  'hp',  'jc',  'jp',  'kk',  'ld',\n",
    "'ai',  'br', 'cm',  'ec',  'ek',  'ig',  'ji',  'kc',  'kn',  'ls',\n",
    "'an',  'ca',  'dc',  'ee',  'es',  'ih',  'jj',  'kf',  'kt'\n",
    "]\n",
    "test_speakers =['mk',  'mm',  'ms',  'mw',  'nc',  'ng',  'nh',  'pe',  'pk',  'pm',  'pp',  'ra'] \n",
    "digits = ['1','4','6','9','o']\n",
    "train_mfcc = {} #dictionary to be addressed with labels\n",
    "test_mfcc = {}\n",
    "\n",
    "for speaker in train_speakers:\n",
    "    for i in digits:\n",
    "        s = speaker+'_'+i+'.wav.mfcc' #generating file name\n",
    "        \n",
    "        with open('MFCC/'+s) as f:\n",
    "            lines = f.readlines() #reading the lines of the mfcc files\n",
    "            \n",
    "        size = np.asarray(list(map(int,lines[0].split()))) #converting the space separated info to an array\n",
    "        dim = size[0]  #dimension of feature vectors = 38\n",
    "        length = size[1] #number of feature vectors in the utterance\n",
    "        mfcc_coeff = np.zeros((length,dim)) #coefficients info row-> feature vector number,column->coefficients\n",
    "        \n",
    "        for i in range(length):\n",
    "            a = np.asarray(list(map(float,lines[i+1].split())))\n",
    "            mfcc_coeff[i] = a\n",
    "            \n",
    "        train_mfcc[s] = mfcc_coeff\n",
    "        \n",
    "for speaker in test_speakers:\n",
    "    for i in digits:\n",
    "        s = speaker+'_'+i+'.wav.mfcc' #generating file name\n",
    "        \n",
    "        with open('MFCC/'+s) as f:\n",
    "            lines = f.readlines() #reading the lines of the mfcc files\n",
    "            \n",
    "        size = np.asarray(list(map(int,lines[0].split()))) #converting the space separated info to an array\n",
    "        dim = size[0]  #dimension of feature vectors = 38\n",
    "        length = size[1] #number of feature vectors in the utterance\n",
    "        mfcc_coeff = np.zeros((length,dim)) #coefficients info row-> feature vector number,column->coefficients\n",
    "        \n",
    "        for i in range(length):\n",
    "            a = np.asarray(list(map(float,lines[i+1].split())))\n",
    "            mfcc_coeff[i] = a\n",
    "            \n",
    "        test_mfcc[s] = mfcc_coeff\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for dynamic time warping\n",
    "\n",
    "def DTW(sample,test):  # function returns DTW cost matrix and the warped path, vertical movement allowed since test could be smaller than sample\n",
    "    n = len(sample)\n",
    "    m = len(test)\n",
    "    d = len(sample[0])\n",
    "    if(d != len(test[0])):\n",
    "        return np.inf,np.inf\n",
    "    else:\n",
    "        phi = np.zeros((n+1,m+1))  #dtw cost matrix\n",
    "        epsilon = np.zeros((n+1,m+1))  #dtw path matrix\n",
    "\n",
    "        #initialisation\n",
    "        for i in range(n+1):\n",
    "            for j in range(m+1):\n",
    "                if(i*j == 0):\n",
    "                    if((i == 0)and(j == 0)):\n",
    "                        phi[i,j] = 0\n",
    "                    else:\n",
    "                        phi[i,j] = np.inf\n",
    "                #recursion\n",
    "                else:\n",
    "                    prev_min = np.min([phi[i-1,j],phi[i,j-1],phi[i-1,j-1]])\n",
    "                    phi[i,j] = np.linalg.norm(sample[i-1,:] - test[j-1,:]) + prev_min #euclidean distance between the feature vectors + previous min val\n",
    "\n",
    "\n",
    "        #backtracking to find optimal warped path\n",
    "        for i in range(n+1):\n",
    "            for j in range(m+1):\n",
    "                i = n-i\n",
    "                j = m-j\n",
    "\n",
    "                if((phi[i-1,j] <= phi[i,j-1])and(phi[i-1,j] <= phi[i-1,j-1])):\n",
    "                    epsilon[i-1,j] = 1\n",
    "                elif((phi[i,j-1] <= phi[i-1,j] )and(phi[i,j-1] <= phi[i-1,j-1] )):\n",
    "                    epsilon[i,j-1] = 1\n",
    "                else:\n",
    "                    epsilon[i-1,j-1] = 1\n",
    "\n",
    "\n",
    "        epsilon[0,0] = 1\n",
    "        epsilon[1,1] = 1 #start together\n",
    "        epsilon[n,m] = 1 #end together\n",
    "\n",
    "        return phi,epsilon\n",
    "            \n",
    "def predictor(score,k=len(train_speakers)): # K-NN based prediction given score matrix \n",
    "    n_digits,n_speaker = score.shape\n",
    "    score_array = [] # score array with all score values\n",
    "    pred_array = np.zeros(k)\n",
    "    for i in range(n_digits):\n",
    "        for j in range(n_speaker):\n",
    "            score_array.append(score[i,j])\n",
    "    score_array = np.asarray(score_array) # converting to numpy array\n",
    "    indices = [b[0] for b in sorted(enumerate(score_array),key=lambda i:i[1])] #indices when sorted in ascending order\n",
    "    \n",
    "    for i in range(k):\n",
    "        index = indices[i]\n",
    "        pred_array[i] = int(index/n_speaker)\n",
    "        \n",
    "    prediction = stats.mode(pred_array) #majority prediction\n",
    "    \n",
    "    return prediction\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Algorithm\n",
    "\n",
    "#K-Means helper functions\n",
    "def dist(x,centroid):   #computes distance between two vectors\n",
    "    distance = np.square(x-centroid).sum()\n",
    "    return distance\n",
    "\n",
    "\n",
    "def closest_centroid(x,centroids):  #computes the index of the closest centroid\n",
    "    distance = []\n",
    "    for i in range(len(centroids)):\n",
    "        distance.append(dist(x,centroids[i]))\n",
    "        \n",
    "    closest_centroid_index = distance.index(min(distance))\n",
    "    return closest_centroid_index \n",
    "\n",
    "def tot_error(data,centroids,assigned_centroids): # returns total error incurred\n",
    "    error = 0\n",
    "    \n",
    "    for i,x in enumerate(data): #i is index, x is value at that index\n",
    "        centroid = centroids[int(assigned_centroids[i])]\n",
    "        error += dist(x,centroid)\n",
    "        \n",
    "    error /= len(data)\n",
    "    return error\n",
    "        \n",
    "    \n",
    "def KMeans(data,n_clusters,niter=50,tolerance = 0.0001):  #niter taken to be 50 as it converges before that\n",
    "    cluster_centroids = np.zeros((n_clusters,data.shape[1]))\n",
    "    assigned_centroids= np.zeros(data.shape[0])\n",
    "    r                 = np.zeros((data.shape[0],n_clusters))\n",
    "    \n",
    "    #initialisation\n",
    "    # assigning the cluster_centroids to random data points\n",
    "    indices = np.random.randint(data.shape[0],size = n_clusters)\n",
    "    \n",
    "    for i,index in enumerate(indices):\n",
    "        cluster_centroids[i] = data[index]\n",
    "        \n",
    "    error = np.zeros(niter)\n",
    "    #Assignment and Update \n",
    "    for n in range(niter):\n",
    "        \n",
    "        #Assignment \n",
    "        for i,x in enumerate(data):\n",
    "            ind = closest_centroid(x,cluster_centroids)\n",
    "            assigned_centroids[i] = ind #storing the assigned centroid\n",
    "            r[i,ind] = 1 #responsibility r[n,k] = 1\n",
    "\n",
    "        #Update\n",
    "        for i in range(n_clusters):\n",
    "            R = 0  #total responsibility R\n",
    "            for j,x in enumerate(data):\n",
    "                cluster_centroids[i] += r[j,i]*x  # Sigma(r[n,k]x[n])\n",
    "                R                    += r[j,i]\n",
    "            cluster_centroids[i] /= R\n",
    "\n",
    "        error[n] = tot_error(data,cluster_centroids,assigned_centroids)\n",
    "        if((error[n]-error[n-1])<tolerance):\n",
    "            break\n",
    "    return cluster_centroids,assigned_centroids,error   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [05:49<00:00, 29.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mk_1.wav.mfcc': '1', 'mk_4.wav.mfcc': '4', 'mk_6.wav.mfcc': '6', 'mk_9.wav.mfcc': '9', 'mk_o.wav.mfcc': 'o', 'mm_1.wav.mfcc': 'o', 'mm_4.wav.mfcc': 'o', 'mm_6.wav.mfcc': '6', 'mm_9.wav.mfcc': '9', 'mm_o.wav.mfcc': 'o', 'ms_1.wav.mfcc': 'o', 'ms_4.wav.mfcc': '4', 'ms_6.wav.mfcc': '6', 'ms_9.wav.mfcc': '9', 'ms_o.wav.mfcc': 'o', 'mw_1.wav.mfcc': '1', 'mw_4.wav.mfcc': '4', 'mw_6.wav.mfcc': '6', 'mw_9.wav.mfcc': '9', 'mw_o.wav.mfcc': 'o', 'nc_1.wav.mfcc': '1', 'nc_4.wav.mfcc': '4', 'nc_6.wav.mfcc': '6', 'nc_9.wav.mfcc': '9', 'nc_o.wav.mfcc': 'o', 'ng_1.wav.mfcc': '1', 'ng_4.wav.mfcc': 'o', 'ng_6.wav.mfcc': '4', 'ng_9.wav.mfcc': '9', 'ng_o.wav.mfcc': 'o', 'nh_1.wav.mfcc': '1', 'nh_4.wav.mfcc': '4', 'nh_6.wav.mfcc': '6', 'nh_9.wav.mfcc': '9', 'nh_o.wav.mfcc': 'o', 'pe_1.wav.mfcc': '1', 'pe_4.wav.mfcc': '4', 'pe_6.wav.mfcc': '6', 'pe_9.wav.mfcc': '9', 'pe_o.wav.mfcc': 'o', 'pk_1.wav.mfcc': '1', 'pk_4.wav.mfcc': '4', 'pk_6.wav.mfcc': '6', 'pk_9.wav.mfcc': '9', 'pk_o.wav.mfcc': 'o', 'pm_1.wav.mfcc': '1', 'pm_4.wav.mfcc': '4', 'pm_6.wav.mfcc': '6', 'pm_9.wav.mfcc': '9', 'pm_o.wav.mfcc': 'o', 'pp_1.wav.mfcc': '1', 'pp_4.wav.mfcc': '4', 'pp_6.wav.mfcc': '6', 'pp_9.wav.mfcc': '9', 'pp_o.wav.mfcc': 'o', 'ra_1.wav.mfcc': '1', 'ra_4.wav.mfcc': '4', 'ra_6.wav.mfcc': '6', 'ra_9.wav.mfcc': '9', 'ra_o.wav.mfcc': 'o'}\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# DTW based digit recognition\n",
    "pred = {}\n",
    "error = 0\n",
    "for speaker in tqdm(test_speakers):\n",
    "    for i in digits:\n",
    "        s_test = speaker+'_'+i+'.wav.mfcc'\n",
    "        score = np.zeros((len(digits),len(train_speakers)))#score matrix with dynamic time warping scores \n",
    "        \n",
    "        for k in range(len(train_speakers)):\n",
    "            speaker2 = train_speakers[k]\n",
    "            for j in range(len(digits)):\n",
    "                    digit = digits[j]\n",
    "                    s_train = speaker2+'_'+digit+'.wav.mfcc'\n",
    "                    #print(train_mfcc[s_train].shape)\n",
    "                    phi = DTW(train_mfcc[s_train],test_mfcc[s_test])[0]\n",
    "                    score[j,k] = phi[-1,-1]\n",
    "        \n",
    "        #making prediction \n",
    "        predicted_index = predictor(score,20)[0]\n",
    "        prediction = digits[int(predicted_index)]\n",
    "        pred[s_test] = prediction\n",
    "        if(prediction != i):\n",
    "            error += 1\n",
    "\n",
    "print(pred)\n",
    "print(error)\n",
    "        \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the K-Means codebook and the observation sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw(s, t):\n",
    "    n, m = len(s), len(t)\n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    for i in range(n+1):\n",
    "        for j in range(m+1):\n",
    "            dtw_matrix[i, j] = np.inf\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            cost = abs(s[i-1] - t[j-1])\n",
    "            # take last min from a square box\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "    return dtw_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2']\n"
     ]
    }
   ],
   "source": [
    "a = ['1','2']\n",
    "b = np.asarray(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1\n"
     ]
    }
   ],
   "source": [
    "c = 'a'+'_'+'1'\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.bool_' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-ea837c7901a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mS_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.bool_' object is not iterable"
     ]
    }
   ],
   "source": [
    "a = np.zeros((5,3))\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        a[i,j] = i+j\n",
    "        \n",
    "S_indices = [b[0] for b in sorted(enumerate(a.all()),key=lambda i:i[1], reverse = True)]\n",
    "print(S_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.min([2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if(i==5):\n",
    "        break\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_mfcc_male' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3f71de8d8cb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_mfcc_male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_mfcc_male' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(test_mfcc_male.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
